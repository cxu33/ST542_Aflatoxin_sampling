library(tidyverse)
library(ggplot2)
library(lme4)
library(scales)
library(reshape2)
library(pbapply)

set.seed(123)

# Fixed simulation settings
nrailcars_per_train <- 200
regulatory_threshold <- 20       # Safety threshold for a railcar
target_safe_proportion <- 0.95    # Train is considered safe if at least 95% of railcars are safe
n_sim <- 1000                   # Number of simulated trains per parameter combination

# Varying parameters
sample_sizes <- c(5, 10, 20, 30, 50, 80, 100, 150, 200)
shape_params <- c(0.2, 0.5, 0.8, 1)
scale_params <- c(3, 5, 10, 12)

# Simulation function for one train load (takes shape and scale as inputs)
simulate_trainload <- function(shape_param, scale_param) {
  gamma_comp <- rgamma(nrailcars_per_train, shape = shape_param, scale = scale_param)
  railcar_effect <- rnorm(nrailcars_per_train, mean = 0, sd = 0.5)  # Small measurement noise
  observed <- gamma_comp + railcar_effect
  observed <- pmax(observed, 0)  # Ensure non-negative values
  
  # If all values are zero (rare), force a minimal contamination
  if (all(observed == 0)) observed[1] <- 0.01
  return(observed)
}

# Simple uniform sampling function
simple_sample <- function(ppb, size) {
  sample(length(ppb), size)
}

# One-sided Wilson score lower bound function
ci_lower_bound <- function(x, conf = 0.95) {
  n <- length(x)
  successes <- sum(x < regulatory_threshold)  # Count of railcars below threshold
  # If sampling the full train, return the actual proportion
  if (n == nrailcars_per_train) return(successes / n)
  
  p_hat <- successes / n
  z <- qnorm(conf)  # one-sided critical value (â‰ˆ1.645 for 95% one-sided)
  lower <- (p_hat + (z^2) / (2 * n) -
              z * sqrt((p_hat * (1 - p_hat)) / n + (z^2) / (4 * n^2))) /
    (1 + (z^2) / n)
  return(lower)
}

# Prepare a data frame to store results
results <- data.frame()

# Loop over each combination of shape, scale, and sample size
total_loops <- length(shape_params) * length(scale_params) * length(sample_sizes)
pb <- txtProgressBar(min = 0, max = total_loops, style = 3)
counter <- 0

for (shape_val in shape_params) {
  for (scale_val in scale_params) {
    for (n_sample in sample_sizes) {
      safe_train_count <- 0    # Truly safe trains (true safe proportion >= target)
      unsafe_train_count <- 0  # Truly unsafe trains (true safe proportion < target)
      false_rejections <- 0    # Truly safe trains wrongly rejected (producer's risk)
      false_acceptances <- 0   # Truly unsafe trains wrongly accepted (consumer's risk)
      accept_count <- 0        # Overall count of trains accepted as safe based on sample decision
      
      for (i in 1:n_sim) {
        ppb <- simulate_trainload(shape_val, scale_val)
        true_prop_safe <- mean(ppb < regulatory_threshold)
        true_safe <- (true_prop_safe >= target_safe_proportion)
        
        sample_idx <- simple_sample(ppb, n_sample)
        sample_ppb <- ppb[sample_idx]
        
        # "Any detection" rule: if any sampled railcar exceeds the threshold, flag unsafe.
        if (any(sample_ppb >= regulatory_threshold)) {
          sample_safe <- FALSE
        } else {
          sample_lower <- ci_lower_bound(sample_ppb, conf = 0.95)
          sample_safe <- (sample_lower >= target_safe_proportion)
        }
        
        if (true_safe) {
          safe_train_count <- safe_train_count + 1
          if (!sample_safe) {  # Truly safe, but sample indicates unsafe
            false_rejections <- false_rejections + 1
          }
        } else {
          unsafe_train_count <- unsafe_train_count + 1
          if (sample_safe) {   # Truly unsafe, but sample indicates safe
            false_acceptances <- false_acceptances + 1
          }
        }
        if (sample_safe) {
          accept_count <- accept_count + 1
        }
      }
      
      producers_risk <- if (safe_train_count > 0) false_rejections / safe_train_count else NA
      consumers_risk <- if (unsafe_train_count > 0) false_acceptances / unsafe_train_count else NA
      overall_acceptance <- accept_count / n_sim
      
      results <- rbind(results, data.frame(
        shape = shape_val,
        scale = scale_val,
        sample_size = n_sample,
        producers_risk = producers_risk,
        consumers_risk = consumers_risk,
        overall_acceptance = overall_acceptance
      ))
      
      counter <- counter + 1
      setTxtProgressBar(pb, counter)
    }
  }
}
close(pb)

# Reshape the results for plotting
results_melt <- melt(results, id.vars = c("shape", "scale", "sample_size"),
                     measure.vars = c("producers_risk", "consumers_risk", "overall_acceptance"),
                     variable.name = "Metric", value.name = "Value")

# Plot the metrics vs sample size with facets for shape and scale
result <- ggplot(results_melt, aes(x = sample_size, y = Value, color = Metric)) +
  geom_line(linewidth = 1) +
  facet_grid(factor(shape) ~ factor(scale), labeller = label_both) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(title = "Inspection Metrics vs Sample Size",
       subtitle = "Facets by Gamma Distribution Shape (rows) and Scale (columns)",
       x = "Sample Size",
       y = "Rate",
       color = "Metric") +
  theme_minimal()
print(result)
